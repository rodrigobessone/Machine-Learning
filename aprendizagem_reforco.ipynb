{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **APRENDIZAGEM POR REFORÇO**"
      ],
      "metadata": {
        "id": "zo4_NBVWMQvE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://gym.openai.com/ "
      ],
      "metadata": {
        "id": "vxK5jFkXgZt3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://gym.openai.com/envs/Taxi-v3/ "
      ],
      "metadata": {
        "id": "zwJaIifT9YtC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Links de referência**"
      ],
      "metadata": {
        "id": "SNKu2HUe9fGW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/ "
      ],
      "metadata": {
        "id": "gJuapuEAMK2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://medium.com/turing-talks/aprendizado-por-refor%C3%A7o-4-gym-d18ac1280628 "
      ],
      "metadata": {
        "id": "lXmTMZJhML9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instalando a Biblioteca GYM**"
      ],
      "metadata": {
        "id": "7swTjEjMHMMl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1nuOSLFMCbKY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf9ae6a2-9c52-42ca-e987-5dff4dad80a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.8/dist-packages (3.22.6)\n",
            "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.8/dist-packages (0.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym[atari]) (5.1.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym[atari]) (1.5.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym[atari]) (0.0.8)\n",
            "Collecting ale-py~=0.7.5\n",
            "  Downloading ale_py-0.7.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from ale-py~=0.7.5->gym[atari]) (5.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym[atari]) (3.11.0)\n",
            "Installing collected packages: ale-py\n",
            "Successfully installed ale-py-0.7.5\n"
          ]
        }
      ],
      "source": [
        "!pip install cmake 'gym[atari]' scipy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym"
      ],
      "metadata": {
        "id": "LRh70CdVChvL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Carregando e renderizando o ambiente**"
      ],
      "metadata": {
        "id": "I4_DwI5tHbq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"Taxi-v3\").env"
      ],
      "metadata": {
        "id": "MvgWNK_uCmCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ec709d6-a667-4db5-b73c-c1e9b6b0abae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## função temporariamente inoperante\n",
        "# env.render()"
      ],
      "metadata": {
        "id": "JKfP0RINDAfA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# redefinindo o ambiente e retornando um estado inicial aleatório.\n",
        "env.reset() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj2ZuAZDDCR4",
        "outputId": "d427c9a0-2ed8-4d6e-a2b0-969736cfe27a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "294"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## função temporariamente inoperante\n",
        "# env.render()"
      ],
      "metadata": {
        "id": "0oB2144rDkDe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "env.reset: redefine o ambiente e retorna um estado inicial aleatório.\n",
        "\n",
        "env.step(action): Apresenta os passos de ação.\n"
      ],
      "metadata": {
        "id": "LXaShm9SIFDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print no espaço de ação discreto e no espaço de estado discreto\n",
        "print(\"Action Space {}\".format(env.action_space))\n",
        "print(\"State Space {}\".format(env.observation_space))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g-pY7BoDwOu",
        "outputId": "cd703c64-8c80-4bc8-e273-ec61e5e11a0f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action Space Discrete(6)\n",
            "State Space Discrete(500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ESPAÇO DE ESTADO**"
      ],
      "metadata": {
        "id": "E8ovsxyiC-sA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Espaço de estado da grade: 5x5 = 25\n",
        "\n",
        "Espaço posição do passageiro: 5 (quatro pontos externos e um dentro do taxi)\n",
        "\n",
        "Espaço de posição de embargue/desembarque (destino): 4\n",
        "\n",
        "Total: 5x5x5x4 = 500 espaços de estado. "
      ],
      "metadata": {
        "id": "ORr0nKOpA9CY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ESPAÇO DE AÇÃO**"
      ],
      "metadata": {
        "id": "eCjLZN58DCy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O algoritmo escolherá um número de ação de 0 a 5, onde:\n",
        "\n",
        "0 = sul\n",
        "\n",
        "1 = norte\n",
        "\n",
        "2 = leste\n",
        "\n",
        "3 = oeste\n",
        "\n",
        "4 = embarque\n",
        "\n",
        "5 = desembarque"
      ],
      "metadata": {
        "id": "j5C0tVoAJwPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Colocando o taxi na linha 3, coluna 1, nosso passageiro no local 2 e nosso destino é o local 0.**"
      ],
      "metadata": {
        "id": "gEn_Sq6RK68T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state = env.encode(3, 1, 2,0) # (linha do taxi, coluna do taxi, índice do passageiro, índice do destino)\n",
        "print(\"State:\", state)\n",
        "\n",
        "env.s = state\n",
        "#env.render() # função temporariamente inoperante"
      ],
      "metadata": {
        "id": "Wr_-TDSJEgFt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52efa970-aa1d-4df5-f1b3-a4ecbf08f484"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State: 328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Táxi amarelo é sem passageiro e verde é com passageiro.\n",
        "\n",
        "A barra (\"|\") representa uma parede que o táxi não pode atravessar.\n",
        "\n",
        "R, G, Y, B são os possíveis locais de coleta e destino. A **letra azul** representa o local de **embargue** do passageiro e a **letra roxa** é o **desembargue** do passageiro."
      ],
      "metadata": {
        "id": "ywJ13rDjJMbf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recompensas (Já definidas na biblioteca):\n",
        "\n",
        "+20 para um desembarque correto.\n",
        "\n",
        "-10 para um embarque ou desembarque incorreto.\n",
        "\n",
        "-1 para ações que não sejam as duas anteriores."
      ],
      "metadata": {
        "id": "6-cTUWHZKW4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env.P[328]"
      ],
      "metadata": {
        "id": "bmWgFuTKEoNj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf20902a-ef3b-4215-9fa4-f6137fbb9b78"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: [(1.0, 428, -1, False)],\n",
              " 1: [(1.0, 228, -1, False)],\n",
              " 2: [(1.0, 348, -1, False)],\n",
              " 3: [(1.0, 328, -1, False)],\n",
              " 4: [(1.0, 328, -10, False)],\n",
              " 5: [(1.0, 328, -10, False)]}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "gSapNw99FFSq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tabela_q = np.zeros([env.observation_space.n, env.action_space.n]) #iniciando a tabela Q"
      ],
      "metadata": {
        "id": "SnRf1JhUFDeR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tabela_q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLUVMJzb6qXp",
        "outputId": "d0673d47-566e-4f77-d06c-226ba013311c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tabela_q.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14WKyz3w61DI",
        "outputId": "31e648cd-df9e-4d8e-9c7d-9be465a5064f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TREINAMENTO DO ALGORITMO**"
      ],
      "metadata": {
        "id": "CeD6Mkl86VL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Não existem valores \"certos\" ou \"errados\", é por tentativa e erro.\n",
        "alpha = 0.1\n",
        "gamma = 0.6\n",
        "epsilon = 0.1 # Determina a chance do agente tomar uma ação aleatória, nesse caso a chance é de 10%\n",
        "\n",
        "for i in range(1, 200001):\n",
        "    estado = env.reset()\n",
        "\n",
        "    episodios, penalidades, recompensa = 0, 0, 0 \n",
        "    terminado = False\n",
        "    \n",
        "    while not terminado:\n",
        "        if random.uniform(0, 1) < epsilon: # Decidindo se será tomada uma ação aleatória ou se seguirá a política da tabela-q\n",
        "            acao = env.action_space.sample() \n",
        "        else:\n",
        "            acao = np.argmax(tabela_q[estado]) \n",
        "\n",
        "        proximo_estado, recompensa, terminado, info = env.step(acao) \n",
        "        \n",
        "        valor_antigo = tabela_q[estado, acao]\n",
        "        proximo_max = np.max(tabela_q[proximo_estado])\n",
        "        \n",
        "        # Atualizando o valor de q a partir da equação de Bellman\n",
        "        valor_novo = (1 - alpha) * valor_antigo + alpha * (recompensa + gamma * proximo_max) \n",
        "        tabela_q[estado, acao] = valor_novo # Colocando este valor na tabela-q\n",
        "\n",
        "        if recompensa == -10: # Contabilizando os embarques/desembarques errados\n",
        "            penalidades += 1\n",
        "\n",
        "        estado = proximo_estado\n",
        "        episodios += 1\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(wait=True)\n",
        "        print(f\"Episódios: {i}\")\n",
        "        \n",
        "print(\"Treinamento terminado.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUwTuTxgFOU6",
        "outputId": "26071750-20bb-4d0b-b279-ab4b3c415a02"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episódios: 200000\n",
            "Treinamento terminado.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AVALIAÇÃO DO ALGORITMO**"
      ],
      "metadata": {
        "id": "XRvVzvzL6k8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_penalidades = 0\n",
        "episodios = 100\n",
        "frames = []\n",
        "\n",
        "for i in range(episodios):\n",
        "  estado = env.reset()\n",
        "  penalidades, recompensa = 0, 0\n",
        "  done = False\n",
        "  while not done:\n",
        "    acao = np.argmax(tabela_q[estado])\n",
        "    estado, recompensa, done, info = env.step(acao)\n",
        "\n",
        "    if recompensa == -10:\n",
        "      penalidades += 1\n",
        "    \n",
        "    frames.append({\n",
        "        'frame': env.render(mode='ansi'),\n",
        "        'state': estado,\n",
        "        'action': acao,\n",
        "        'reward': recompensa\n",
        "    })\n",
        "\n",
        "  total_penalidades += penalidades\n",
        "\n",
        "print('Episódios', episodios)\n",
        "print('Penalidades', total_penalidades)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hl4PZe4Q1M0i",
        "outputId": "6fb197cb-73ab-4ce1-e1a4-c9d980a24ef5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episódios 100\n",
            "Penalidades 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from time import sleep\n",
        "for frame in frames:\n",
        "  clear_output(wait=True)\n",
        "  print(frame['frame'])\n",
        "  print('Estado', frame['state'])\n",
        "  print('Ação', frame['action'])\n",
        "  print('Recompensa', frame['reward'])\n",
        "  sleep(.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZU5Kh861xvp",
        "outputId": "60976a31-ddcc-4d2d-c1bf-d6b5ae6ffd9d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|\u001b[35m\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "\n",
            "Estado 0\n",
            "Ação 5\n",
            "Recompensa 20\n"
          ]
        }
      ]
    }
  ]
}